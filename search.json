[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, Iâ€™m Onur Kerimoglu. Iâ€™m a data scientist with a backround in ecosystem modelling research, based in Hamburg, Germany (and thatâ€™s our pretty Alster behind me on my profile picture)."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Welcome to my Quarto blog!\nHere I am planning to write about my ongoing projects, recipes, what worked and what not, in hopes that these will be helpful for someone out there, or my future self ðŸ˜ƒ\nEnjoy!\n\n\n\nImage credit: DreamStudio"
  },
  {
    "objectID": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#detect-trend-and-seasonality",
    "href": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#detect-trend-and-seasonality",
    "title": "Bayesian MMM",
    "section": "Detect Trend and Seasonality",
    "text": "Detect Trend and Seasonality\nLetâ€™s first detect the trend ans seasonility in the data, which we will use as control variables in our model.\n\nprophet_data = data_wdates.rename(columns = {'revenue': 'y', 'start_of_week': 'ds'})\n\nprophet = Prophet(yearly_seasonality=True, weekly_seasonality=False)\n\nprophet.fit(prophet_data[[\"ds\", \"y\"]])\nprophet_predict = prophet.predict(prophet_data[[\"ds\", \"y\"]])\n\nINFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\nDEBUG:cmdstanpy:input tempfile: /tmp/tmpr0x5f6xf/587rqks_.json\nDEBUG:cmdstanpy:input tempfile: /tmp/tmpr0x5f6xf/ngpqm7ps.json\nDEBUG:cmdstanpy:idx 0\nDEBUG:cmdstanpy:running CmdStan, num_threads: None\nDEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=51446', 'data', 'file=/tmp/tmpr0x5f6xf/587rqks_.json', 'init=/tmp/tmpr0x5f6xf/ngpqm7ps.json', 'output', 'file=/tmp/tmpr0x5f6xf/prophet_modelpp0cy47i/prophet_model-20230203181838.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n18:18:38 - cmdstanpy - INFO - Chain [1] start processing\nINFO:cmdstanpy:Chain [1] start processing\n18:18:38 - cmdstanpy - INFO - Chain [1] done processing\nINFO:cmdstanpy:Chain [1] done processing\n\n\n\nplot = prophet.plot_components(prophet_predict, figsize = (20, 10))\n\n\n\n\nAdding the detected trend and seasonality signals back to the data table:\n\nprophet_columns = [col for col in prophet_predict.columns if (col.endswith(\"upper\") == False) & (col.endswith(\"lower\") == False)]\n\nfinal_data = data_wdates.copy()\nfinal_data[\"trend\"] = prophet_predict[\"trend\"]\nfinal_data[\"season\"] = prophet_predict[\"yearly\"]\n\nThe final feature (X) and target (y) data:\n\nX = final_data.drop(columns=['revenue', 'start_of_week'])\ny = final_data['revenue']"
  },
  {
    "objectID": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#carryover-adstock",
    "href": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#carryover-adstock",
    "title": "Bayesian MMM",
    "section": "Carryover (adstock)",
    "text": "Carryover (adstock)\nFor modelling carryover, following Jin et al.Â 2017, we use an adstock function of the form:\n\\[\nx^*_{t,m} = \\frac{\\sum_l w_m(l)x_{t-l,m}}{\\sum_l w_m(l)}\n\\]\nHere, \\(w_m\\) is a nonnegative weight function, which can be described with a geometric decay function, i.e.,\n\\[\nw_m = \\alpha_m^l, l = 0, 1, ..., L-1, 0<\\alpha_m<1\n\\]\nwhere, \\(w_m\\) describes the weight of the effect on each time step \\(l\\), that lasts for \\(L\\) time steps (which we here prescribe to be 13 time steps, i.e., weeks, which is a good approximation for infinity according to Jin et al.Â 2017), and \\(\\alpha_m\\) is the decay rate for the channel \\(m\\).\n\ndef carryover(x, strength, length=13):\n    w = tt.as_tensor_variable(\n        [tt.power(strength, i) for i in range(length)]\n    )\n    \n    x_lags = tt.stack(\n        [tt.concatenate([tt.zeros(i),x[:x.shape[0]-i]]) for i in range(length)]\n    )\n    \n    return tt.dot(w, x_lags)"
  },
  {
    "objectID": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#the-additive-model",
    "href": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#the-additive-model",
    "title": "Bayesian MMM",
    "section": "The additive model",
    "text": "The additive model\nNext, we build a model that consists of delayed media channels and control variables:\n\\[\ny_t = \\epsilon + \\tau  +  \\sum_c \\gamma_c z_{t,c} + \\sum_m  \\beta_m x^*_{t,m}\n\\]\nwhere, \\(\\epsilon\\) and \\(\\tau\\) represent noise and baseline revenue, \\(z_{t,c}\\) and \\(\\gamma\\) represent the control variable \\(c\\) and their effects, and \\(x^*_{t,m}\\) and \\(\\beta_m\\) represent the (adstocked) media spending \\(m\\) and their effects, respectively.\nNote that here for simplicity, we assume no shape effects (i.e., no saturation). We further assume that marketing contributions can only be positive, which can be achieved by drawing the contribution coefficient from a half-normal distribution.\n\ncontrol_variables = [\"trend\", \"season\"]\ndelay_channels = [f'spend_channel_{i}' for i in range(1,8)]\ntransform_variables = control_variables+delay_channels\n\ny_transformed=y/10000 #rescale target variable\n\nX_transformed = X.copy() #Min-max scale the features\n\nnumerical_encoder_dict = {}\nfor feature in transform_variables:\n    scaler = MinMaxScaler()\n    original = final_data[feature].values.reshape(-1, 1)\n    transformed = scaler.fit_transform(original)\n    X_transformed[feature] = transformed\n    numerical_encoder_dict[feature] = scaler\n\nwith pm3.Model() as mmm1:\n    channel_contributions = []\n    \n    for channel in delay_channels:\n        print(f\"Delay channels: Adding {channel}\")\n        #Force the channel coefficients to be normal:\n        coef = pm3.HalfNormal(f'coef_{channel}', sigma = 2)\n        car = pm3.Beta(f'car_{channel}', alpha=2, beta=2)\n      \n        channel_data = X_transformed[channel].values\n        channel_contribution = pm3.Deterministic(\n            f'contribution_{channel}',\n            coef * carryover(\n                    channel_data,\n                    car),\n            )\n        \n        channel_contributions.append(channel_contribution)\n    \n    control_contributions = []\n    for control_var in control_variables:\n        print(f\"Control Variables: Adding {control_var}\")\n  \n        x = X_transformed[control_var].values\n  \n        control_beta = pm3.Normal(f\"control_{control_var}\", sigma = 3)\n        control_x = control_beta * x\n        control_contributions.append(control_x)\n\n    base = pm3.Normal(\"base\", np.mean(y_transformed.values), sigma = 2)\n    #base = pm3.Exponential('base', lam=0.01)\n    noise = pm3.Exponential('noise', lam=0.1)\n\n    sales = pm3.Normal(\n        'sales',\n        mu= base + sum(control_contributions) + sum(channel_contributions),\n        sigma=noise,\n        observed=y_transformed\n    )\n\nDelay channels: Adding spend_channel_1\nDelay channels: Adding spend_channel_2\nDelay channels: Adding spend_channel_3\nDelay channels: Adding spend_channel_4\nDelay channels: Adding spend_channel_5\nDelay channels: Adding spend_channel_6\nDelay channels: Adding spend_channel_7\nControl Variables: Adding trend\nControl Variables: Adding season"
  },
  {
    "objectID": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#do-the-prior-distributions-make-sense",
    "href": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#do-the-prior-distributions-make-sense",
    "title": "Bayesian MMM",
    "section": "Do the prior distributions make sense?",
    "text": "Do the prior distributions make sense?\nWe can check whether the model estimates based on priors more or less make sense, as can be judged from a rough alignment of the corresponding estimates with the observations.\n\nwith mmm1:\n    prior_pred = pm3.sample_prior_predictive()\nprior_names = [prior_name for prior_name in list(prior_pred.keys()) if (prior_name.endswith(\"logodds__\") == False) & (prior_name.endswith(\"_log__\") == False)]\nfig, ax = plt.subplots(figsize = (20, 8))\n_ = ax.plot(prior_pred[\"sales\"].T, color = \"0.5\", alpha = 0.1)\n_ = ax.plot(y_transformed.values, color = \"red\")\n\n\n\n\nCheck the prior distributions:\n\n#plots priors using the random variables\ndef plot_priors(variables, prior_dictionary = None):\n    if isinstance(variables[0], pm3.model.TransformedRV) == False and prior_dictionary is None:\n        raise Exception(\"prior dictionary should be provided. It can be generated by sample_prior_predictive\")\n    cols = 7\n    rows = int(math.ceil(len(variables)/cols))\n    fig, ax = plt.subplots(rows, cols, figsize=(15, 3*rows))\n    ax = np.reshape(ax, (-1, cols))\n    for i in range(rows):\n         for j in range(cols):\n            vi = i*cols + j\n            if vi < len(variables):\n                var = variables[vi]\n                if isinstance(var, pm3.model.TransformedRV):\n                    sns.histplot(var.random(size=10000).flatten(), kde=True, ax=ax[i, j])\n                    #p.set_axis_labels(var.name)\n                    ax[i, j].set_title(var.name)\n                else:\n                    prior = prior_dictionary[var]\n                    sns.histplot(prior, kde=True, ax = ax[i, j])\n                    ax[i, j].set_title(var)\n    plt.tight_layout()\n    \n\nadstock_priors = [p for p in prior_names if p.startswith(\"car\")]\nplot_priors(adstock_priors, prior_pred)\nprint(f\"carryover priors: {len(adstock_priors)}\")\n\n# alpha_priors = [p for p in prior_names if p.startswith(\"sat\")]\n# plot_priors(alpha_priors, prior_pred)\n# print(f\"sat priors: {len(alpha_priors)}\")\n\nmedia_coef_priors = [p for p in prior_names if p.startswith(\"coef\")]\nplot_priors(media_coef_priors, prior_pred)\nprint(f\"coef priors: {len(media_coef_priors)}\")\n\ncontrol_coef_priors = [p for p in prior_names if p.startswith(\"control_\")] + [\"base\"]\nplot_priors(control_coef_priors, prior_pred)\nprint(f\"control coef priors: {len(control_coef_priors)}\")\n\n#plot_priors([\"sigma\"], prior_pred)\n\nprint(f\"sigma prior: 1\")\n\ncarryover priors: 7\ncoef priors: 7\ncontrol coef priors: 3\nsigma prior: 1"
  },
  {
    "objectID": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#fit-the-model",
    "href": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#fit-the-model",
    "title": "Bayesian MMM",
    "section": "Fit the model",
    "text": "Fit the model\n\nwith mmm1:\n  trace = pm3.sample(return_inferencedata=True, tune=3000, target_accept=0.95)\n  trace_summary = az.summary(trace)\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 01:26<00:00 Sampling chain 0, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 01:32<00:00 Sampling chain 1, 0 divergences]\n    \n    \n\n\n/usr/local/lib/python3.8/dist-packages/arviz/stats/diagnostics.py:586: RuntimeWarning: invalid value encountered in double_scalars\n  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n/usr/local/lib/python3.8/dist-packages/arviz/stats/diagnostics.py:586: RuntimeWarning: invalid value encountered in double_scalars\n  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n\n\n\ntrace_summary\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n      mcse_mean\n      mcse_sd\n      ess_bulk\n      ess_tail\n      r_hat\n    \n  \n  \n    \n      control_trend\n      2.064\n      1.975\n      -1.338\n      6.022\n      0.045\n      0.034\n      1950.0\n      1481.0\n      1.0\n    \n    \n      control_season\n      4.766\n      1.782\n      1.472\n      8.229\n      0.040\n      0.029\n      1974.0\n      1484.0\n      1.0\n    \n    \n      base\n      6.855\n      1.123\n      4.674\n      8.888\n      0.030\n      0.022\n      1341.0\n      1462.0\n      1.0\n    \n    \n      coef_spend_channel_1\n      0.926\n      0.769\n      0.004\n      2.342\n      0.014\n      0.010\n      1665.0\n      880.0\n      1.0\n    \n    \n      car_spend_channel_1\n      0.445\n      0.219\n      0.064\n      0.830\n      0.003\n      0.003\n      3865.0\n      1264.0\n      1.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      contribution_spend_channel_7[100]\n      0.463\n      0.326\n      0.002\n      1.030\n      0.007\n      0.005\n      1351.0\n      839.0\n      1.0\n    \n    \n      contribution_spend_channel_7[101]\n      0.611\n      0.418\n      0.004\n      1.377\n      0.010\n      0.007\n      1270.0\n      825.0\n      1.0\n    \n    \n      contribution_spend_channel_7[102]\n      0.628\n      0.430\n      0.004\n      1.422\n      0.010\n      0.007\n      1271.0\n      825.0\n      1.0\n    \n    \n      contribution_spend_channel_7[103]\n      0.676\n      0.462\n      0.004\n      1.526\n      0.011\n      0.008\n      1259.0\n      817.0\n      1.0\n    \n    \n      noise\n      3.930\n      0.302\n      3.351\n      4.467\n      0.007\n      0.005\n      1977.0\n      1417.0\n      1.0\n    \n  \n\n746 rows Ã— 9 columns"
  },
  {
    "objectID": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#posterior-distributions",
    "href": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#posterior-distributions",
    "title": "Bayesian MMM",
    "section": "Posterior distributions",
    "text": "Posterior distributions\n\naz.plot_posterior(\n    trace,\n    var_names=['~contribution'],\n    filter_vars='like'\n)\n\narray([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fefc4e301c0>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fefc24cea00>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fefc24fb520>],\n       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fefc245b760>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fefc23de130>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fefca987e20>],\n       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fefc2342430>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fefc22fff40>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fefc22265b0>],\n       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fefc08b2640>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fefc02ea580>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fefc025aa30>],\n       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fefc09fdb20>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fefc0983d00>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fefc0966880>],\n       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fefc96f2820>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fefc961feb0>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fefc1476d00>]],\n      dtype=object)"
  },
  {
    "objectID": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#predictions-vs-observations",
    "href": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#predictions-vs-observations",
    "title": "Bayesian MMM",
    "section": "Predictions vs Observations",
    "text": "Predictions vs Observations\nWe can now check the model skill by plotting the predictions and observations together, and calculating, e.g., MAE.\n\nwith mmm1:\n    posterior = pm3.sample_posterior_predictive(trace)\n\n\n\n\n\n\n    \n      \n      100.00% [2000/2000 00:40<00:00]\n    \n    \n\n\n\ny_pred = posterior['sales'].mean(0)*10000\ny_stds = posterior['sales'].std(0)*10000\n\nMAE = mean_absolute_error(y.values, y_pred)\nMAPE = mean_absolute_percentage_error(y.values, y_pred)*100\nSkillStr = 'MAE: %5d\\nMAPE: %5.2f%%'%(MAE,MAPE)\nfig, ax = plt.subplots(figsize=(12, 6))\nplt.subplots_adjust(left=0.15,\n                        bottom=0.15,\n                        right=0.95,\n                        top=0.9)\nax.plot(y.values, linewidth=2, c='r', label='Observations')\nax.plot(y_pred, linewidth=1, c='b', label='Mean prediction')\nax.fill_between(np.arange(len(y)), y_pred - 2*y_stds, y_pred + 2*y_stds, alpha=0.33)\nax.text(0.85,0.9,SkillStr, transform=ax.transAxes)\nax.legend(loc='upper center')\nax.set_xlabel('Week')\nax.set_ylabel('Revenue')\nplt.show()\n\n\n\n\nExcept for two weeks, the observations lay within 2 standard deviations plus/minus the predictions. That instance is likely due to a special event, like a promotion or a holiday, which is not accounted for by the model. The mean absolute error corresponds to about 20% of the revenue."
  },
  {
    "objectID": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#channel-contributions-and-roi",
    "href": "posts/bayesian_mmm/bayesian_mmm_example_enhanced_newdataset.html#channel-contributions-and-roi",
    "title": "Bayesian MMM",
    "section": "Channel Contributions and ROI",
    "text": "Channel Contributions and ROI\n\ndef compute_mean(trace, channel):\n    return (trace\n            .posterior[f'{channel}']\n            .values\n            .reshape(2000, 104)\n            .mean(0)\n           )\n\nchannels = [f'contribution_spend_channel_{i}' for i in range(1,8)]\n\nunadj_contributions = pd.DataFrame(\n    {'Base+Trend+Seas': trace.posterior['base'].values.mean()\n                 +trace.posterior['control_trend'].values.mean()\n                 +trace.posterior['control_season'].values.mean()},\n    index=X.index\n)\n\nfor channel in channels:\n    unadj_contributions[channel] = compute_mean(trace, channel)\n\nadj_contributions = (unadj_contributions\n                     .div(unadj_contributions.sum(axis=1), axis=0)\n                     .mul(y, axis=0)\n                    )\n\nax = (adj_contributions\n      .plot.area(\n          figsize=(12, 6),\n          linewidth=1,\n          title='Predicted Revenue and Breakdown',\n          ylabel='Revenue',\n          xlabel='Week'\n      )\n     )\n    \nhandles, labels = ax.get_legend_handles_labels()\nax.legend(\n    handles[::-1], labels[::-1],\n    title='Channels', loc=\"upper right\",\n    #bbox_to_anchor=(1.01, 0.5)\n)\nplt.show()\n\n\n\n\nAccording to this plot, the model suggests that a large portion of the revenue is not explained by marketing actions.\nFor each channel \\(m\\), percentage \\(ROI_m\\) can be calculated according to:\n\\[\nROI_m = \\frac{\\sum_t C_{t,m} - \\sum_t S_{t,m}}{\\sum_t S_{t,m}} * 100\n\\]\nwhere \\(C_{t,m}\\) and \\(S_{t,m}\\) are the revenue contribution and spends to the media channel \\(m\\) at a given time step \\(t\\).\n\n#Calculate ROI for each channel\ntotal_contr = adj_contributions.sum(axis=0)\ntotal_spend = X.sum(axis=0)\n\nCchannels = [f'contribution_spend_channel_{i}' for i in range(1,8)]\n            \nSchannels = [f'spend_channel_{i}' for i in range(1,8)]\n\nROI_l= [None] * 7\nspend_l = [None] * 7\ncontr_l = [None] * 7\nfor i in range(7):\n    spend_l[i] = total_spend[Schannels[i]]\n    contr_l[i] = total_contr[Cchannels[i]]\n    ROI_l[i] = (contr_l[i] - spend_l[i])/spend_l[i] *100\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 10))\nax1.bar(np.arange(1,8) - 0.2, spend_l, color = 'r', width = 0.4, label='Spend')\nax1.bar(np.arange(1,8) + 0.2, contr_l, color = 'b', width = 0.4, label='Contr')\nax1.set_xlabel('Marketing Channel')\nax1.set_ylabel('Contribution and Spends')\nax1.legend(loc='upper left')\n\nax2.bar(range(1,8),ROI_l)\nax2.set_xlabel('Marketing Channel')\nax2.set_ylabel('ROI (%)')\n\nplt.show()\n\n\n\n\nOur model suggests that only channels 1, 2 and 6 generate positive net gains. Among these channels, 2 seems most effective in terms of ROI, however, in terms of absolute revenue contribution, channel 6 is the most important source. Among the channels that results in net costs channel 7 is the one that requires most immediate attenion, both in terms of ROI and absolute net cost. Continued investment in channels 3 and 4 seem also questionable."
  },
  {
    "objectID": "saved4later/bayesian_mmm_example_enhanced_newdataset.html#extract-trend-and-seasonality",
    "href": "saved4later/bayesian_mmm_example_enhanced_newdataset.html#extract-trend-and-seasonality",
    "title": "Bayesian MMM",
    "section": "Extract Trend and Seasonality",
    "text": "Extract Trend and Seasonality\n\nfrom prophet import Prophet\n\n\nprophet_data = data_wdates.rename(columns = {'revenue': 'y', 'start_of_week': 'ds'})\n\nprophet = Prophet(yearly_seasonality=True, weekly_seasonality=False)\n\nprophet.fit(prophet_data[[\"ds\", \"y\"]])\nprophet_predict = prophet.predict(prophet_data[[\"ds\", \"y\"]])\n\nINFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\nDEBUG:cmdstanpy:input tempfile: /tmp/tmpgikvg02q/hlf0pv09.json\nDEBUG:cmdstanpy:input tempfile: /tmp/tmpgikvg02q/b5gcq0ux.json\nDEBUG:cmdstanpy:idx 0\nDEBUG:cmdstanpy:running CmdStan, num_threads: None\nDEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.8/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=10532', 'data', 'file=/tmp/tmpgikvg02q/hlf0pv09.json', 'init=/tmp/tmpgikvg02q/b5gcq0ux.json', 'output', 'file=/tmp/tmpgikvg02q/prophet_model68mgz_lw/prophet_model-20230126104611.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n10:46:11 - cmdstanpy - INFO - Chain [1] start processing\nINFO:cmdstanpy:Chain [1] start processing\n10:46:11 - cmdstanpy - INFO - Chain [1] done processing\nINFO:cmdstanpy:Chain [1] done processing\n\n\n\nplot = prophet.plot_components(prophet_predict, figsize = (20, 10))\n\n\n\n\n\nprophet_columns = [col for col in prophet_predict.columns if (col.endswith(\"upper\") == False) & (col.endswith(\"lower\") == False)]\nevents_numeric = prophet_predict[prophet_columns].filter(like = \"events_\").sum(axis = 1)\n\nfinal_data = data_wdates.copy()\nfinal_data[\"trend\"] = prophet_predict[\"trend\"]\nfinal_data[\"season\"] = prophet_predict[\"yearly\"]\n\n\nX = final_data.drop(columns=['revenue', 'start_of_week'])\ny = final_data['revenue']"
  },
  {
    "objectID": "saved4later/bayesian_mmm_example_enhanced_newdataset.html#do-the-prior-distributions-make-sense",
    "href": "saved4later/bayesian_mmm_example_enhanced_newdataset.html#do-the-prior-distributions-make-sense",
    "title": "Bayesian MMM",
    "section": "Do the prior distributions make sense?",
    "text": "Do the prior distributions make sense?\n\nwith mmm1:\n    prior_pred = pm3.sample_prior_predictive()\nprior_names = [prior_name for prior_name in list(prior_pred.keys()) if (prior_name.endswith(\"logodds__\") == False) & (prior_name.endswith(\"_log__\") == False)]\nfig, ax = plt.subplots(figsize = (20, 8))\n_ = ax.plot(prior_pred[\"sales\"].T, color = \"0.5\", alpha = 0.1)\n_ = ax.plot(y_transformed.values, color = \"red\")\n\nWARNING:theano.tensor.blas:We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\nWARNING:theano.tensor.blas:We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n\n\n\n\n\n\n#plots priors using the random variables\ndef plot_priors(variables, prior_dictionary = None):\n    if isinstance(variables[0], pm3.model.TransformedRV) == False and prior_dictionary is None:\n        raise Exception(\"prior dictionary should be provided. It can be generated by sample_prior_predictive\")\n    cols = 7\n    rows = int(math.ceil(len(variables)/cols))\n    fig, ax = plt.subplots(rows, cols, figsize=(15, 3*rows))\n    ax = np.reshape(ax, (-1, cols))\n    for i in range(rows):\n         for j in range(cols):\n            vi = i*cols + j\n            if vi < len(variables):\n                var = variables[vi]\n                if isinstance(var, pm3.model.TransformedRV):\n                    sns.histplot(var.random(size=10000).flatten(), kde=True, ax=ax[i, j])\n                    #p.set_axis_labels(var.name)\n                    ax[i, j].set_title(var.name)\n                else:\n                    prior = prior_dictionary[var]\n                    sns.histplot(prior, kde=True, ax = ax[i, j])\n                    ax[i, j].set_title(var)\n    plt.tight_layout()\n    \n\nadstock_priors = [p for p in prior_names if p.startswith(\"car\")]\nplot_priors(adstock_priors, prior_pred)\nprint(f\"carryover priors: {len(adstock_priors)}\")\n\n# alpha_priors = [p for p in prior_names if p.startswith(\"sat\")]\n# plot_priors(alpha_priors, prior_pred)\n# print(f\"sat priors: {len(alpha_priors)}\")\n\nmedia_coef_priors = [p for p in prior_names if p.startswith(\"coef\")]\nplot_priors(media_coef_priors, prior_pred)\nprint(f\"coef priors: {len(media_coef_priors)}\")\n\ncontrol_coef_priors = [p for p in prior_names if p.startswith(\"control_\")] + [\"base\"]\nplot_priors(control_coef_priors, prior_pred)\nprint(f\"control coef priors: {len(control_coef_priors)}\")\n\n#plot_priors([\"sigma\"], prior_pred)\n\nprint(f\"sigma prior: 1\")\n\ncarryover priors: 7\ncoef priors: 7\ncontrol coef priors: 3\nsigma prior: 1"
  },
  {
    "objectID": "saved4later/bayesian_mmm_example_enhanced_newdataset.html#fit-the-model",
    "href": "saved4later/bayesian_mmm_example_enhanced_newdataset.html#fit-the-model",
    "title": "Bayesian MMM",
    "section": "Fit the model",
    "text": "Fit the model\n\nwith mmm1:\n  trace = pm3.sample(return_inferencedata=True, tune=3000, target_accept=0.95)\n  trace_summary = az.summary(trace)\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 01:16<00:00 Sampling chain 0, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 01:15<00:00 Sampling chain 1, 0 divergences]\n    \n    \n\n\n/usr/local/lib/python3.8/dist-packages/arviz/stats/diagnostics.py:586: RuntimeWarning: invalid value encountered in double_scalars\n  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n\n\n\ntrace_summary\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      mean\n      sd\n      hdi_3%\n      hdi_97%\n      mcse_mean\n      mcse_sd\n      ess_bulk\n      ess_tail\n      r_hat\n    \n  \n  \n    \n      control_trend\n      2.226\n      2.019\n      -1.785\n      5.763\n      0.048\n      0.038\n      1738.0\n      1562.0\n      1.0\n    \n    \n      control_season\n      4.750\n      1.860\n      1.397\n      8.340\n      0.040\n      0.028\n      2176.0\n      1508.0\n      1.0\n    \n    \n      base\n      6.811\n      1.206\n      4.585\n      9.033\n      0.030\n      0.021\n      1646.0\n      1513.0\n      1.0\n    \n    \n      coef_spend_channel_1\n      0.915\n      0.777\n      0.005\n      2.268\n      0.017\n      0.012\n      1317.0\n      833.0\n      1.0\n    \n    \n      car_spend_channel_1\n      0.446\n      0.214\n      0.063\n      0.806\n      0.004\n      0.003\n      2634.0\n      1449.0\n      1.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      contribution_spend_channel_7[100]\n      0.481\n      0.323\n      0.000\n      1.034\n      0.008\n      0.006\n      1404.0\n      848.0\n      1.0\n    \n    \n      contribution_spend_channel_7[101]\n      0.635\n      0.414\n      0.000\n      1.346\n      0.010\n      0.007\n      1376.0\n      767.0\n      1.0\n    \n    \n      contribution_spend_channel_7[102]\n      0.651\n      0.424\n      0.001\n      1.382\n      0.010\n      0.007\n      1388.0\n      767.0\n      1.0\n    \n    \n      contribution_spend_channel_7[103]\n      0.701\n      0.456\n      0.000\n      1.486\n      0.011\n      0.008\n      1385.0\n      767.0\n      1.0\n    \n    \n      noise\n      3.919\n      0.306\n      3.376\n      4.498\n      0.007\n      0.005\n      1978.0\n      1310.0\n      1.0\n    \n  \n\n746 rows Ã— 9 columns"
  },
  {
    "objectID": "saved4later/bayesian_mmm_example_enhanced_newdataset.html#posterior-distributions",
    "href": "saved4later/bayesian_mmm_example_enhanced_newdataset.html#posterior-distributions",
    "title": "Bayesian MMM",
    "section": "Posterior distributions",
    "text": "Posterior distributions\n\naz.plot_posterior(\n    trace,\n    var_names=['~contribution'],\n    filter_vars='like'\n)\n\narray([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fabda7341f0>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fabda6135e0>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fabda3fd820>],\n       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fabda5197f0>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fabda2ba340>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fabd96bab20>],\n       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fabd9662e50>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fabd96eee20>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fabd9090a60>],\n       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fabd8ffd820>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fabd7e2bf70>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fabd9dd2a90>],\n       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fabd9ccf670>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fabd9cef880>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fabd9c244f0>],\n       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fabd9d9f4f0>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fabd9e3adf0>,\n        <matplotlib.axes._subplots.AxesSubplot object at 0x7fabdab3aa90>]],\n      dtype=object)"
  },
  {
    "objectID": "saved4later/bayesian_mmm_example_enhanced_newdataset.html#predictions-vs-observations",
    "href": "saved4later/bayesian_mmm_example_enhanced_newdataset.html#predictions-vs-observations",
    "title": "Bayesian MMM",
    "section": "Predictions vs Observations",
    "text": "Predictions vs Observations\n\nwith mmm1:\n    posterior = pm3.sample_posterior_predictive(trace)\n\n\n\n\n\n\n    \n      \n      100.00% [2000/2000 00:28<00:00]\n    \n    \n\n\n\ny_pred = posterior['sales'].mean(0)*10000\ny_stds = posterior['sales'].std(0)*10000\n\nMAE = mean_absolute_error(y.values, y_pred)\nMAPE = mean_absolute_percentage_error(y.values, y_pred)*100\nSkillStr = 'MAE: %5d\\nMAPE: %5.2f%%'%(MAE,MAPE)\nfig, ax = plt.subplots(figsize=(12, 6))\nplt.subplots_adjust(left=0.15,\n                        bottom=0.15,\n                        right=0.95,\n                        top=0.9)\nax.plot(y.values, linewidth=2, c='r', label='Observations')\nax.plot(y_pred, linewidth=1, c='b', label='Mean prediction')\nax.fill_between(np.arange(len(y)), y_pred - 2*y_stds, y_pred + 2*y_stds, alpha=0.33)\nax.text(0.85,0.9,SkillStr, transform=ax.transAxes)\nax.legend(loc='upper center')\nax.set_xlabel('Week')\nax.set_ylabel('Revenue')\nplt.show()"
  },
  {
    "objectID": "saved4later/bayesian_mmm_example_enhanced_newdataset.html#channel-contributions-and-roi",
    "href": "saved4later/bayesian_mmm_example_enhanced_newdataset.html#channel-contributions-and-roi",
    "title": "Bayesian MMM",
    "section": "Channel Contributions and ROI",
    "text": "Channel Contributions and ROI\n\ndef compute_mean(trace, channel):\n    return (trace\n            .posterior[f'{channel}']\n            .values\n            .reshape(2000, 104)\n            .mean(0)\n           )\n\nchannels = [f'contribution_spend_channel_{i}' for i in range(1,8)]\n\nunadj_contributions = pd.DataFrame(\n    {'Base+Trend+Seas': trace.posterior['base'].values.mean()\n                 +trace.posterior['control_trend'].values.mean()\n                 +trace.posterior['control_season'].values.mean()},\n    index=X.index\n)\n\nfor channel in channels:\n    unadj_contributions[channel] = compute_mean(trace, channel)\n\nadj_contributions = (unadj_contributions\n                     .div(unadj_contributions.sum(axis=1), axis=0)\n                     .mul(y, axis=0)\n                    )\n\nax = (adj_contributions\n      .plot.area(\n          figsize=(12, 6),\n          linewidth=1,\n          title='Predicted Revenue and Breakdown',\n          ylabel='Revenue',\n          xlabel='Week'\n      )\n     )\n    \nhandles, labels = ax.get_legend_handles_labels()\nax.legend(\n    handles[::-1], labels[::-1],\n    title='Channels', loc=\"upper right\",\n    #bbox_to_anchor=(1.01, 0.5)\n)\nplt.show()\n\n\n\n\n\n#Calculate ROI for each channel\ntotal_contr = adj_contributions.sum(axis=0)\ntotal_spend = X.sum(axis=0)\n\nCchannels = [f'contribution_spend_channel_{i}' for i in range(1,8)]\n            \nSchannels = [f'spend_channel_{i}' for i in range(1,8)]\n\nROI_l= [None] * 7\nspend_l = [None] * 7\ncontr_l = [None] * 7\nfor i in range(7):\n    spend_l[i] = total_spend[Schannels[i]]\n    contr_l[i] = total_contr[Cchannels[i]]\n    ROI_l[i] = (contr_l[i] - spend_l[i])/spend_l[i] *100\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 10))\nax1.bar(np.arange(1,8) - 0.2, spend_l, color = 'r', width = 0.4, label='Spend')\nax1.bar(np.arange(1,8) + 0.2, contr_l, color = 'b', width = 0.4, label='Contr')\nax1.set_xlabel('Marketing Channel')\nax1.set_ylabel('Contribution and Spends')\nax1.legend(loc='upper left')\n\nax2.bar(range(1,8),ROI_l)\nax2.set_xlabel('Marketing Channel')\nax2.set_ylabel('ROI (%)')\n\nplt.show()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OnurKerimoglu.github.io",
    "section": "",
    "text": "Bayesian MMM\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nFeb 3, 2023\n\n\nOnur Kerimoglu\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\nOnur Kerimoglu\n\n\n\n\n\n\nNo matching items"
  }
]